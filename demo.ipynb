{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Aerial Image Classification Demo\n",
                "\n",
                "This notebook demonstrates how to load and use the pre-trained models for aerial image classification.\n",
                "We provide two types of models:\n",
                "1. **Classic Machine Learning**: Bag of Features (BoF) with different algorithms (Softmax, SVM, Decision Tree, Random Forest, NaÃ¯ve Bayes).\n",
                "2. **Deep Learning**: A custom ResNet-based Convolutional Neural Network (CNN).\n",
                "\n",
                "## Prerequisites\n",
                "Ensure you have the necessary dependencies installed:\n",
                "```bash\n",
                "pip install torch torchvision scikit-learn opencv-python joblib huggingface_hub matplotlib\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import joblib\n",
                "import torch\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from torchvision import transforms\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from huggingface_hub import hf_hub_download\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Local imports\n",
                "from classicML.visual_pipeline import *\n",
                "from NeuralNets.model import PiattiCNN"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "classic-ml-header",
            "metadata": {},
            "source": [
                "## 1. Classic Machine Learning Model (BoVW)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "load-classic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Classic ML Model loaded successfully.\n"
                    ]
                }
            ],
            "source": [
                "# Download and load the Classic ML model from Hugging Face\n",
                "classic_model_path = hf_hub_download(\n",
                "    repo_id=\"JavideuS/aid-image-classification\",\n",
                "    filename=\"classicML/models/bovw_softmax.pkl\"\n",
                ")\n",
                "\n",
                "bundle = joblib.load(classic_model_path)\n",
                "pipeline = bundle['pipeline']\n",
                "le = bundle['label_encoder']\n",
                "\n",
                "print(\"Classic ML Model loaded successfully.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "predict-classic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_classic(image_path):\n",
                "    \"\"\"\n",
                "    Predicts the class of an image using the Classic ML pipeline.\n",
                "    \"\"\"\n",
                "    if not os.path.exists(image_path):\n",
                "        print(f\"Error: Image not found at {image_path}\")\n",
                "        return\n",
                "\n",
                "    # The pipeline expects a list of paths\n",
                "    pred_int = pipeline.predict([image_path])\n",
                "    pred_label = le.inverse_transform(pred_int)\n",
                "\n",
                "    # print(f\"[Classic ML] Prediction for {os.path.basename(image_path)}: {pred_label[0]}\")\n",
                "    return pred_label[0]\n",
                "\n",
                "# Example Usage\n",
                "# predict_classic(\"path/to/your/image.jpg\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cnn-header",
            "metadata": {},
            "source": [
                "## 2. Deep Learning Model (CNN)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "load-cnn",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CNN Model loaded successfully on cuda.\n"
                    ]
                }
            ],
            "source": [
                "# Download and load the CNN model from Hugging Face\n",
                "cnn_model_path = hf_hub_download(\n",
                "    repo_id=\"JavideuS/aid-image-classification\",\n",
                "    filename=\"neuralNet/models/PiattiVL_v0.69.pth\"\n",
                ")\n",
                "\n",
                "checkpoints = torch.load(cnn_model_path, map_location='cpu')\n",
                "cnn_model = PiattiCNN(num_classes=checkpoints['num_classes'])\n",
                "cnn_model.load_state_dict(checkpoints['model_state_dict'])\n",
                "cnn_model.eval()\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "cnn_model.to(device)\n",
                "\n",
                "print(f\"CNN Model loaded successfully on {device}.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "predict-cnn",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the preprocessing transform (must match training)\n",
                "# Funny enough this transformation performs better than tes\n",
                "eval_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "def predict_cnn(image_path):\n",
                "    \"\"\"\n",
                "    Predicts the class of an image using the CNN model.\n",
                "    \"\"\"\n",
                "    if not os.path.exists(image_path):\n",
                "        print(f\"Error: Image not found at {image_path}\")\n",
                "        return\n",
                "\n",
                "    # Load and preprocess image\n",
                "    image = Image.open(image_path).convert('RGB')\n",
                "    image_tensor = eval_transform(image).unsqueeze(0).to(device)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        outputs = cnn_model(image_tensor)\n",
                "        _, predicted = torch.max(outputs, 1)\n",
                "\n",
                "    # Assuming we have the class names from the dataset or label encoder\n",
                "    # For now, we reuse the label encoder from the classic model if available,\n",
                "    # or just print the index if not.\n",
                "    try:\n",
                "        class_name = le.inverse_transform([predicted.item()])[0]\n",
                "    except NameError:\n",
                "        class_name = str(predicted.item())\n",
                "\n",
                "    # print(f\"[CNN] Prediction for {os.path.basename(image_path)}: {class_name}\")\n",
                "    return class_name\n",
                "\n",
                "# Example Usage\n",
                "# predict_cnn(\"path/to/your/image.jpg\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "comparison-header",
            "metadata": {},
            "source": [
                "## 3. Comparative Evaluation\n",
                "\n",
                "In this section, we load the raw dataset, split it into training and testing sets, and evaluate both models on the test set to compare their **Accuracy** and **Inference Time**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "data-loading",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 10000 images in 30 categories\n",
                        "Test Set Size: 2000 images\n"
                    ]
                }
            ],
            "source": [
                "# 1. Load Dataset Paths\n",
                "image_paths =  []\n",
                "labels = []\n",
                "# If you don't have the dataset, please run python download_dataset.py\n",
                "source_dir = 'data/raw'\n",
                "\n",
                "if os.path.exists(source_dir):\n",
                "    categories = [d for d in os.listdir(source_dir)\n",
                "                  if os.path.isdir(os.path.join(source_dir, d))]\n",
                "    for category in categories:\n",
                "        category_path = os.path.join(source_dir, category)\n",
                "        files = [os.path.join(category_path, f) for f in os.listdir(category_path)\n",
                "                 if os.path.isfile(os.path.join(category_path, f))]\n",
                "        image_paths.extend(files)\n",
                "        labels.extend([category] * len(files))\n",
                "\n",
                "    print(f\"Found {len(image_paths)} images in {len(categories)} categories\")\n",
                "\n",
                "    # 2. Encode Labels\n",
                "    labels_encoded = le.transform(labels)\n",
                "\n",
                "    # 3. Split Data\n",
                "    X_train, X_test, y_train, y_test = train_test_split(image_paths, labels_encoded, test_size=0.2, random_state=0, stratify=labels)\n",
                "    print(f\"Test Set Size: {len(X_test)} images\")\n",
                "else:\n",
                "    print(f\"Warning: '{source_dir}' directory not found. Please ensure the dataset is downloaded and extracted there to run the comparison.\")\n",
                "    X_test = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "evaluation-loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Evaluating Classic ML on 2000 images...\n",
                        "Evaluating CNN on 2000 images...\n",
                        "\n",
                        "=============================================\n",
                        "Model           | Accuracy   | Time (s)  \n",
                        "---------------------------------------------\n",
                        "Classic ML      | 0.6330     | 97.00\n",
                        "CNN             | 0.9580     | 17.36\n",
                        "=============================================\n"
                    ]
                }
            ],
            "source": [
                "if len(X_test) > 0:\n",
                "    # --- Classic ML Evaluation ---\n",
                "    print(f\"Evaluating Classic ML on {len(X_test)} images...\")\n",
                "    t0 = time.time()\n",
                "    y_pred_classic = pipeline.predict(X_test)\n",
                "    t_classic = time.time() - t0\n",
                "    acc_classic = accuracy_score(y_test, y_pred_classic)\n",
                "\n",
                "    # --- CNN Evaluation ---\n",
                "    class SimpleDataset(Dataset):\n",
                "        def __init__(self, paths, labels, transform):\n",
                "            self.paths = paths\n",
                "            self.labels = labels\n",
                "            self.transform = transform\n",
                "        def __len__(self): return len(self.paths)\n",
                "        def __getitem__(self, idx):\n",
                "            img = Image.open(self.paths[idx]).convert('RGB')\n",
                "            return self.transform(img), self.labels[idx]\n",
                "\n",
                "    test_dataset = SimpleDataset(X_test, y_test, eval_transform)\n",
                "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
                "\n",
                "    print(f\"Evaluating CNN on {len(X_test)} images...\")\n",
                "    cnn_preds = []\n",
                "    cnn_targets = []\n",
                "    t0 = time.time()\n",
                "    with torch.no_grad():\n",
                "        for images, labels in test_loader:\n",
                "            images = images.to(device)\n",
                "            outputs = cnn_model(images)\n",
                "            _, predicted = torch.max(outputs, 1)\n",
                "            cnn_preds.extend(predicted.cpu().numpy())\n",
                "            cnn_targets.extend(labels.numpy())\n",
                "    t_cnn = time.time() - t0\n",
                "    acc_cnn = accuracy_score(cnn_targets, cnn_preds)\n",
                "\n",
                "    # --- Results ---\n",
                "    print(\"\\n\" + \"=\"*45)\n",
                "    print(f\"{'Model':<15} | {'Accuracy':<10} | {'Time (s)':<10}\")\n",
                "    print(\"-\" * 45)\n",
                "    print(f\"{'Classic ML':<15} | {acc_classic:.4f}     | {t_classic:.2f}\")\n",
                "    print(f\"{'CNN':<15} | {acc_cnn:.4f}     | {t_cnn:.2f}\")\n",
                "    print(\"=\"*45)\n",
                "else:\n",
                "    print(\"Skipping evaluation (no data found).\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
